{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "981b6e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1438 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'norm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 84\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccess!!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     82\u001b[0m     save_json(Text_Dict,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m levircc.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 84\u001b[0m \u001b[43mmake_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 80\u001b[0m, in \u001b[0;36mmake_texts\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     77\u001b[0m     IMA \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/A/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     78\u001b[0m     IMB \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/B/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 80\u001b[0m     Text_Dict[image_name] \u001b[38;5;241m=\u001b[39m \u001b[43mPrompt_Maker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIMA\u001b[49m\u001b[43m,\u001b[49m\u001b[43mIMB\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnot_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccess!!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     82\u001b[0m save_json(Text_Dict,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m levircc.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 58\u001b[0m, in \u001b[0;36mPrompt_Maker\u001b[0;34m(Initial_Image, Final_Image, model, preprocess, not_done, device)\u001b[0m\n\u001b[1;32m     56\u001b[0m     text_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode_text(TEXT)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(IMAGE\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 58\u001b[0m     logits_per_image, logits_per_text \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIMAGE\u001b[49m\u001b[43m,\u001b[49m\u001b[43mTEXT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     probs \u001b[38;5;241m=\u001b[39m logits_per_image\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#print(type(Outputs))   \u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/RSCaMa_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/RSCaMa_env/lib/python3.9/site-packages/clip/model.py:367\u001b[0m, in \u001b[0;36mCLIP.forward\u001b[0;34m(self, image, text)\u001b[0m\n\u001b[1;32m    364\u001b[0m text_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_text(text)\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# normalized features\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m image_features \u001b[38;5;241m=\u001b[39m image_features \u001b[38;5;241m/\u001b[39m \u001b[43mimage_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    368\u001b[0m text_features \u001b[38;5;241m=\u001b[39m text_features \u001b[38;5;241m/\u001b[39m text_features\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# cosine similarity as logits\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'norm'"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device\n",
    "model1,preprocess = clip.load('ViT-B/16',device='cuda:0')\n",
    "from PIL import Image\n",
    "import os\n",
    "import concurrent.futures\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path) as f:\n",
    "        file = json.load(f)\n",
    "    f.close()\n",
    "    return file\n",
    "def save_json(file,path):\n",
    "    with open(path,'w') as f:\n",
    "        json.dump(file,f)\n",
    "    f.close()\n",
    "    print(\"Saved Successfully\")\n",
    "def rem_print(word):\n",
    "    t_word = word\n",
    "    for _ in range(100 - len(t_word)):\n",
    "        word = word + ' '\n",
    "    print(word,end='\\r')\n",
    "    \n",
    "# Text \n",
    "\n",
    "def Prompt_Maker(Initial_Image,Final_Image,model,preprocess,not_done=False,device='cpu'):\n",
    "    Outputs = [[\"remote sensing image foreground objects\"],\n",
    "               [\"remote sensing image background objects\"],\n",
    "               [\"remote sensing image foreground objects\"],\n",
    "               [\"remote sensing image background objects\"]]\n",
    "    \n",
    "    Classes = [\"Beach\",\"Forest\",\"Lake\",\"Meadow\",\"Mountain\",\"Sea\",\"Wetland\",\"Cotton Field\",\"Farmland\",\"Prairie\",\"Desert\",\n",
    "           \"River\",\"Tree\",\"Shrubbery\",\"Chaparral\",\" Fertile Land\",\"Snow Land\",\"Pond\",\"Island Airport\",\"Bridge\",\"Freeway\",\n",
    "           \"Harbor\",\"Railway\",\"Interchange\",\"Intersection\",\"Road\",\"Highway\",\"Basketball Court\",\"Ground Track Field\",\"Stadium\",\n",
    "           \"TennisCourt\",\"Golf Course\",\"Dense Residential\",\"Single-Family Residential\",\"Building\",\"Church\",\"Cabin\",\"Commercial Area\",\n",
    "           \"Industrial Area\",\"Oil Tank\",\"Storage Tanks\",\"Container\",\"Mine Terrace\",\"Campus\",\"Park\",\"Parking Lot\",\"Square\",\"Solar Panel\",\n",
    "           \"Cars\",\"Ship Airplane\",\"Runway\",\"Impermeable Surface\"]\n",
    "    \n",
    "    TEXT= clip.tokenize(Classes).to(device)\n",
    "    images = [Initial_Image,Final_Image]\n",
    "   \n",
    "    for i in range(len(images)):\n",
    "        if not_done:\n",
    "            IMAGE = Image.open(images[i])\n",
    "            #print(type(IMAGE))\n",
    "            IMAGE = preprocess(IMAGE).unsqueeze(0).to(device)\n",
    "        else:\n",
    "            IMAGE = images[i]\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            image_features,pos = model.encode_image(IMAGE)\n",
    "            text_features = model.encode_text(TEXT)\n",
    "            print(IMAGE.shape)\n",
    "            logits_per_image, logits_per_text = model(IMAGE,TEXT)\n",
    "            probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "        #print(type(Outputs))   \n",
    "        Outputs[2*i][0] += (\",\")\n",
    "        for index in np.argsort(probs)[0][::-1][:9]:\n",
    "            #results.append()\n",
    "            Outputs[2*i][0] += Classes[index]\n",
    "            Outputs[2*i][0] += \",\"\n",
    "        Outputs[2*i][0] = Outputs[2*i][0][:-1]\n",
    "    return Outputs\n",
    "\n",
    "\n",
    "def make_texts(args):\n",
    "    folder,device,model = args\n",
    "    Directory = 'data/Levir-CC-dataset/images'\n",
    "    Text_Dict = {}\n",
    "\n",
    "    for image_name in tqdm(os.listdir(f'{Directory}/{folder}/A')):\n",
    "        \n",
    "        IMA = f'{Directory}/{folder}/A/{image_name}'\n",
    "        IMB = f'{Directory}/{folder}/B/{image_name}'\n",
    "        \n",
    "        Text_Dict[image_name] = Prompt_Maker(IMA,IMB,model=model,preprocess=preprocess,not_done=True,device=device)\n",
    "        print('success!!')\n",
    "    save_json(Text_Dict,f'text {folder} levircc.json')\n",
    "    \n",
    "make_texts(('val','cuda:0',model1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RSCaMa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
