{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/anaconda3/envs/RSCaMa_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.optim\n",
    "from torch.utils import data\n",
    "import argparse\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import clip\n",
    "sys.path.append('/home/guest/Documents/Siraj TM/RSCaMa')\n",
    "from model.model_encoder_attMamba import Encoder, AttentiveEncoder\n",
    "from model.model_decoder import DecoderTransformer\n",
    "from utils_tool.utils import *\n",
    "from data.LEVIR_CC.LEVIRCC import LEVIRCCDataset\n",
    "from torch import nn, einsum\n",
    "\n",
    "from PIL import Image\n",
    "from imageio import imread\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 31 16:24:33 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A5000               Off |   00000000:65:00.0 Off |                  Off |\n",
      "| 30%   42C    P8             11W /  230W |   11142MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA RTX A5000               Off |   00000000:B3:00.0 Off |                  Off |\n",
      "| 30%   40C    P8              9W /  230W |      27MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1673      G   /usr/lib/xorg/Xorg                             99MiB |\n",
      "|    0   N/A  N/A      1862    C+G   ...libexec/gnome-remote-desktop-daemon        205MiB |\n",
      "|    0   N/A  N/A      2013      G   ...3/usr/bin/snapd-desktop-integration         33MiB |\n",
      "|    0   N/A  N/A    284524      G   ...r/anaconda3/envs/Goutham/bin/python         27MiB |\n",
      "|    0   N/A  N/A    871151      C   /home/user/resnet_snn/bin/python            10562MiB |\n",
      "|    0   N/A  N/A   1060472      G   /usr/lib/xorg/Xorg                             64MiB |\n",
      "|    0   N/A  N/A   1060506      G   /usr/bin/gnome-shell                            8MiB |\n",
      "|    1   N/A  N/A      1673      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "|    1   N/A  N/A   1060472      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    with open(path) as f:\n",
    "        file = json.load(f)\n",
    "    f.close()\n",
    "    return file\n",
    "def save_json(file,path):\n",
    "    with open(path,'w') as f:\n",
    "        json.dump(file,f)\n",
    "    f.close()\n",
    "    print(\"Saved Successfully\")\n",
    "def rem_print(word):\n",
    "    t_word = word\n",
    "    for _ in range(100 - len(t_word)):\n",
    "        word = word + ' '\n",
    "    print(word,end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vocab = load_json('assets/vocab.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/Levir-CC-dataset/images/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from torch.nn.utils.rnn import pack_padded_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(\n",
    "                LEVIRCCDataset('CLIP-ViT-B/32','data/Levir-CC-dataset/images', '/home/guest/Documents/Siraj TM/RSCaMa/data/LEVIR_CC/', 'train', '/home/guest/Documents/Siraj TM/RSCaMa/data/LEVIR_CC/tokens/', word_vocab, 42, 1),\n",
    "                batch_size=64, shuffle=True, num_workers=24, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = data.DataLoader(\n",
    "                LEVIRCCDataset('CLIP-ViT-B/32','data/Levir-CC-dataset/images', '/home/guest/Documents/Siraj TM/RSCaMa/data/LEVIR_CC/', 'val', '/home/guest/Documents/Siraj TM/RSCaMa/data/LEVIR_CC/tokens/', word_vocab , 42, 1),\n",
    "                batch_size=64, shuffle=False, num_workers=24, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_n_layers= 1\n",
      "decoder_type= transformer_decoder\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder('CLIP-ViT-B/32')\n",
    "encoder.fine_tune(True)\n",
    "encoder_trans = AttentiveEncoder(n_layers=3,\n",
    "                                        feature_size=[7, 7, 768],\n",
    "                                        heads=8, dropout=0.1)\n",
    "decoder = DecoderTransformer(decoder_type='transformer_decoder',embed_dim=768,\n",
    "                                    vocab_size=len(word_vocab), max_lengths=42,\n",
    "                                    word_vocab=word_vocab, n_head=8,\n",
    "                                    n_layers=1, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 31 16:25:59 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A5000               Off |   00000000:65:00.0 Off |                  Off |\n",
      "| 30%   42C    P8             11W /  230W |   11142MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA RTX A5000               Off |   00000000:B3:00.0 Off |                  Off |\n",
      "| 30%   43C    P8              9W /  230W |    4114MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1673      G   /usr/lib/xorg/Xorg                             99MiB |\n",
      "|    0   N/A  N/A      1862    C+G   ...libexec/gnome-remote-desktop-daemon        205MiB |\n",
      "|    0   N/A  N/A      2013      G   ...3/usr/bin/snapd-desktop-integration         33MiB |\n",
      "|    0   N/A  N/A    284524      G   ...r/anaconda3/envs/Goutham/bin/python         27MiB |\n",
      "|    0   N/A  N/A    871151      C   /home/user/resnet_snn/bin/python            10562MiB |\n",
      "|    0   N/A  N/A   1060472      G   /usr/lib/xorg/Xorg                             64MiB |\n",
      "|    0   N/A  N/A   1060506      G   /usr/bin/gnome-shell                            8MiB |\n",
      "|    1   N/A  N/A      1673      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "|    1   N/A  N/A   1060472      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "|    1   N/A  N/A   1144493      C   ...naconda3/envs/RSCaMa_env/bin/python       4082MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = torch.optim.Adam(params=encoder.parameters(),\n",
    "                                            lr=1e-4) if True else None\n",
    "encoder_trans_optimizer = torch.optim.Adam(\n",
    "    params=filter(lambda p: p.requires_grad, encoder_trans.parameters()),\n",
    "    lr=1e-4)\n",
    "decoder_optimizer = torch.optim.Adam(\n",
    "    params=filter(lambda p: p.requires_grad, decoder.parameters()),\n",
    "    lr=1e-4)\n",
    "\n",
    "# Move to GPU, if available\n",
    "encoder.cuda(device)\n",
    "encoder_trans.cuda(device)\n",
    "decoder.cuda(device)\n",
    "encoder_lr_scheduler = torch.optim.lr_scheduler.StepLR(encoder_optimizer, step_size=5,\n",
    "                                                            gamma=1.0) if True else None\n",
    "encoder_trans_lr_scheduler = torch.optim.lr_scheduler.StepLR(encoder_trans_optimizer, step_size=5,\n",
    "                                                                    gamma=1.0)\n",
    "decoder_lr_scheduler = torch.optim.lr_scheduler.StepLR(decoder_optimizer, step_size=5,\n",
    "                                                            gamma=1.0)\n",
    "hist = np.zeros((num_epochs*2 * len(train_loader), 5))\n",
    "\n",
    "l_resizeA = torch.nn.Upsample(size = (256, 256), mode ='bilinear', align_corners = True)\n",
    "l_resizeB = torch.nn.Upsample(size = (256, 256), mode ='bilinear', align_corners = True)\n",
    "index_i = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.train()\n",
    "encoder_trans.train()\n",
    "decoder.train()\n",
    "criterion_cap = torch.nn.CrossEntropyLoss().cuda(device)\n",
    "criterion_cap_cls = torch.nn.CrossEntropyLoss().cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#Feat1 and Feat2\u001b[39;00m\n\u001b[1;32m     27\u001b[0m feat1, feat2 \u001b[38;5;241m=\u001b[39m encoder(imgA, imgB)\n\u001b[0;32m---> 28\u001b[0m feat \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_trans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m scores, caps_sorted, decode_lengths, sort_ind \u001b[38;5;241m=\u001b[39m decoder(feat, token, token_len)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Since we decoded starting with <start>, the targets are all words after <start>, up to <end>\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/RSCaMa_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Siraj TM/RSCaMa/model/model_encoder_attMamba.py:230\u001b[0m, in \u001b[0;36mAttentiveEncoder.forward\u001b[0;34m(self, img_A, img_B)\u001b[0m\n\u001b[1;32m    227\u001b[0m h, w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh_feat, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_feat\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# 1. A B feature from backbone  NLD\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m img_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_pos_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_A\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m img_B \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_pos_embedding(img_B)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# captioning\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Siraj TM/RSCaMa/model/model_encoder_attMamba.py:215\u001b[0m, in \u001b[0;36mAttentiveEncoder.add_pos_embedding\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    213\u001b[0m pos_h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(h)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m    214\u001b[0m pos_w \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(w)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m--> 215\u001b[0m embed_h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_h\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m embed_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh_embedding(pos_w)\n\u001b[1;32m    217\u001b[0m pos_embedding \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([embed_w\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(h, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    218\u001b[0m                            embed_h\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, w, \u001b[38;5;241m1\u001b[39m)],\n\u001b[1;32m    219\u001b[0m                           dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/RSCaMa_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/RSCaMa_env/lib/python3.9/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/RSCaMa_env/lib/python3.9/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print_freq = 100\n",
    "EPOCHS = num_epochs\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for id,batch_data in enumerate(train_loader):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        accum_steps = 64//64\n",
    "        \n",
    "        #Getting Data and moving to GPU if possible\n",
    "        imgA = batch_data['imgA']\n",
    "        imgB = batch_data['imgB']\n",
    "        token = batch_data['token']\n",
    "        token_len = batch_data['token_len']\n",
    "        imgA = imgA.cuda(device)\n",
    "        imgB = imgB.cuda(device)\n",
    "        token = token.cuda(device)\n",
    "        token_len = token_len.cuda(device)\n",
    "        \n",
    "        #Feat1 and Feat2\n",
    "        feat1, feat2 = encoder(imgA, imgB)\n",
    "        feat = encoder_trans(feat1, feat2)\n",
    "        scores, caps_sorted, decode_lengths, sort_ind = decoder(feat, token, token_len)\n",
    "        # Since we decoded starting with <start>, the targets are all words after <start>, up to <end>\n",
    "        targets = caps_sorted[:, 1:]\n",
    "        \n",
    "        scores = pack_padded_sequence(scores, decode_lengths, batch_first=True).data\n",
    "        targets = pack_padded_sequence(targets, decode_lengths, batch_first=True).data\n",
    "        \n",
    "        loss = criterion_cap(scores, targets.to(torch.int64))\n",
    "        \n",
    "        loss = loss / accum_steps\n",
    "        loss.backward()\n",
    "        \n",
    "        if (id + 1) % accum_steps == 0 or (id + 1) == len(train_loader):\n",
    "            decoder_optimizer.step()\n",
    "            encoder_trans_optimizer.step()\n",
    "            if encoder_optimizer is not None:\n",
    "                encoder_optimizer.step()\n",
    "\n",
    "            # Adjust learning rate\n",
    "            decoder_lr_scheduler.step()\n",
    "            encoder_trans_lr_scheduler.step()\n",
    "            if encoder_lr_scheduler is not None:\n",
    "                encoder_lr_scheduler.step()\n",
    "\n",
    "            decoder_optimizer.zero_grad()\n",
    "            encoder_trans_optimizer.zero_grad()\n",
    "            if encoder_optimizer is not None:\n",
    "                encoder_optimizer.zero_grad()\n",
    "                \n",
    "        hist[index_i, 0] = time.time() - start_time #batch_time\n",
    "        hist[index_i, 1] = loss.item()  # train_loss\n",
    "        hist[index_i, 2] = accuracy_v0(scores, targets, 5) #top5\n",
    "        \n",
    "        index_i += 1\n",
    "        \n",
    "        if index_i % (print_freq/10) == 0:\n",
    "            rem_print(f'Training Epoch: {epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 31 16:17:56 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A5000               Off |   00000000:65:00.0 Off |                  Off |\n",
      "| 30%   44C    P8             10W /  230W |   11142MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA RTX A5000               Off |   00000000:B3:00.0 Off |                  Off |\n",
      "| 30%   36C    P8              9W /  230W |      27MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1673      G   /usr/lib/xorg/Xorg                             99MiB |\n",
      "|    0   N/A  N/A      1862    C+G   ...libexec/gnome-remote-desktop-daemon        205MiB |\n",
      "|    0   N/A  N/A      2013      G   ...3/usr/bin/snapd-desktop-integration         33MiB |\n",
      "|    0   N/A  N/A    284524      G   ...r/anaconda3/envs/Goutham/bin/python         27MiB |\n",
      "|    0   N/A  N/A    871151      C   /home/user/resnet_snn/bin/python            10562MiB |\n",
      "|    0   N/A  N/A   1060472      G   /usr/lib/xorg/Xorg                             64MiB |\n",
      "|    0   N/A  N/A   1060506      G   /usr/bin/gnome-shell                            8MiB |\n",
      "|    1   N/A  N/A      1673      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "|    1   N/A  N/A   1060472      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RSCaMa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
